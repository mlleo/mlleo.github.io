---
title: "[Google_Bootcamp_Day6]"
categories: 
  - ML
last_modified_at: 2020-10-26 12:00:00
comments: true
use_math: true # MathJax On
---

#### Train/dev/test set
![1](https://user-images.githubusercontent.com/62474292/102901239-bb2aa880-44b0-11eb-8979-fec803afcbd1.png)

#### Mismatched train/test distribution (real life)
![2](https://user-images.githubusercontent.com/62474292/102901240-bbc33f00-44b0-11eb-9fa6-8ce59e815213.png)
- Make sure that dev and test sets come from the same distribution

#### Bias and Variance
![3](https://user-images.githubusercontent.com/62474292/102901244-bc5bd580-44b0-11eb-9d0f-5390c61ff426.png)
![4](https://user-images.githubusercontent.com/62474292/102901237-b9f97b80-44b0-11eb-969c-7214cbdf666f.png)

#### Basic recipe for machine learning
- Check "high bias" (training set performance)
  - Try bigger network
  - Try to train longer
  - Try different nerual network architecture
- Check "high variance" (dev set performance)
  - Try to use more data
  - Try regularization
  - Try different neural network architecture
  
#### Regularization
- Logistic regression
![5](https://user-images.githubusercontent.com/62474292/102901245-bc5bd580-44b0-11eb-8e11-9c984d5817f5.png)

- Neural network
![6](https://user-images.githubusercontent.com/62474292/102901243-bbc33f00-44b0-11eb-8287-2dba8fcaa305.png)

#### How doe regularization prevent overfitting
![regul](https://user-images.githubusercontent.com/62474292/102902806-c979c400-44b2-11eb-9cd0-55810283d736.png)

#### Dropout regularization
![drop_1](https://user-images.githubusercontent.com/62474292/102913830-ae16b500-44c2-11eb-9442-573f69e575da.png)
![drop_2](https://user-images.githubusercontent.com/62474292/102913836-af47e200-44c2-11eb-80d5-60ddbf46e6cb.png)
- No dropout when making predictions at test time

#### Why dropout work
![reason](https://user-images.githubusercontent.com/62474292/102914145-35642880-44c3-11eb-9b10-bbd1cdffe661.png)

#### Downside and solution
- Downside
  - not well defined cost function so that it is hard to check downhill plot of cost function
- Solution
  - Turn off dropout and check downhill plotting
  - Then turn on dropout


#### Other regularization methods
- Data Augmentation
![aug](https://user-images.githubusercontent.com/62474292/102902814-cb438780-44b2-11eb-879f-9e01c011a7b9.png)

- Early Stopping
![early](https://user-images.githubusercontent.com/62474292/102902812-caaaf100-44b2-11eb-835a-8eec640167de.png)





[Source] https://www.coursera.org/learn/deep-neural-network
