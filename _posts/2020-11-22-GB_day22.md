---
title: "[Google_Bootcamp_Day22]"
categories: 
  - ML
last_modified_at: 2020-11-22 12:00:00
comments: true
use_math: true # MathJax On
---

Convolutional Neural Network3

#### 1 * 1 convolutions
- Network in network
- Use 1 * 1 convolution when you want to shrink the size of channel
- similar as fully-connected layer

#### Inception Network
- Idea : let the network learn whatever parameters it wants to use, whatever the combinations of these filter sizes it wants

- Problem : Computational cost
- Solution : using 1 * 1 convolution


#### Inception Module


#### Practical Advice
- Use open-source implementations
- Use Transer Learning
  - Freeze pre-trained model and train last few layers that you want to target
  - If dataset = large, freeze few layers then train others
  - If dataset = very large, initialize weights with pre-trained weights, then train the whole pre-trained model
- Data Augmentation
  - Mirroring on the vertical axis
  - Random cropping
  - Color Shifting
  - Rotation
  - Shearing
  - Local Warping
 
