---
title: "[Google_Bootcamp_Day17]"
categories: 
  - ML
last_modified_at: 2020-11-12 12:00:00
comments: true
use_math: true # MathJax On
---
ML strategy 3

#### Error Analysis
- Assume that you have 90% accuracy (10% error) cat classifier, and you want to know whether you should try to make your cat classifier do better on dogs or not
- Error Analysis
  - ex. Get 100 mislabeld dev set examples, and count up each categories.
  ![error](https://user-images.githubusercontent.com/62474292/101439375-b665e080-3957-11eb-8128-bd0d1b476bcb.png)
  - Overall dev set error : 10%
  - Errors due incorrect labels : 6% * 10% = 0.6% (relatively small! If it is big, then try to fix it)
  - Errors due to other causes: 9.4%
  - Improve performance on the biggest percentage of error categories (correct label, etc.)
- DL algorithms are quite robust to random errors in the training set (need to care about dev/test set)
- Apply same process to your dev and test sets to **make sure they continue to come from the same distribution**
- Train and dev/test data may now come from slightly different distributions (don't matter!)

#### Build your first system quickly, then iterate

Depending on the area of application, the guideline below will help you prioritize when you build your system.

- Guideline
  1. Set up development/test set and metrics
    - Set up a target
  2. Build an initial system quickly
    - Train training set quickly: Fit the parameters
    - Development set: Tune the parameters
    - Test set: Assess the performance
  3. Use bias/variance analysis & Error analysis to prioritize next steps
  
#### Training and testing on different distributions

Example: Cat vs. Non-cat 


In this example, we want to create a mobile application that will classify and recognize pictures of cats taken and uploaded by users. <br>
There are two sources of data used to develop the mobile app. The first data distribution is small, 10,000 pictures uploaded from the mobile application. Since they are from amateur users, the pictures are not professionally shot, not well framed and blurrier. The second source is from the web, you downloaded 200,000 pictures where cat's pictures are professionally framed and in high resolution. <br><br>

- Option 1 (random shuffle : not recommended)
  - Pros: all data set come from same distribution
  - Cons: most of data in dev set come from "webpages", which means optimizing for wrong target
- Option 2 (let all of the dev/test set come from "mobile app": **recommended**)


  - Pros: target is well defined
  - Cons: training distribution is different from the dev/test set distributions

[Source] https://www.coursera.org/learn/machine-learning-projects
