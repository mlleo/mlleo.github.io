---
title: "[GCP ML engineer certification Day2]"
categories: 
  - ML
last_modified_at: 2020-11-18 12:00:00
comments: true
use_math: true # MathJax On
---

Recommending Products using Cloud SQL and Spark

### Google Cloud Products
1. Cloud SQL - manged relational database
2. Cloud dataproc - managed environment on which you can run Apache Spark

### Why we migrate an on-premise application to Google Cloud platform?
1. to avoid the challenges that are associated with utilizing and tuning on-premise clusters.
2. when you move an on-premise application to Google Cloud, you're also moving from dedicated storage to off-cluster storage with Google Cloud Storage.

### The core pieces of a recommendation system
- data
- model
- infrastructure to train and serve recommendations to users

#### A core tenet of machine learning is to let the model learn for itself what the relationship is.

![query](https://user-images.githubusercontent.com/62474292/99483358-5c4dad00-29a1-11eb-83a9-ddc6782c081e.JPG)
- Hand-coded rules are hard to maintain. <br>
- Why can't we train a machine learning model to basically provide a ranking of these links? <br>
- That's exactly what Google itself did internally with a deep learning model called Rank Brain.

***Machine Learning = exmaples, not rules***

### Concept of Recommendation System
![recommendation](https://user-images.githubusercontent.com/62474292/99637235-e2dcba00-2a87-11eb-898b-9d14eaa76379.JPG)
1. ingest the ratings of all the houses that have already been done by our users when we showed them specific houses.
  - explicit ratings : showed the house to the user in the past and they've clicked four stars after seeing the house details.
  - implicit ratings : user spent a lot of time looking at the website corresponding to this property.
2. Training
3. pick the top five rated houses that they haven't already seen.

### How the recommendation models work
The model is based on two things.
- based on your other ratings, what have you rated other houses.
- based on other people's rating of this particular house. <br>
This idea of using user ratings of a particular house and users like you helps convey the basic premise of how recommendation models work.

### Things that you have to consider
- how to find the users who are most like you
- how many users to consider
- how to weight the different factos such as the overall popularity of the items you have in common <br>

This can be done by seeing what parameters help predict if you intentionally withheld ratings best. 

### Things that machine learning model consider
![cluster](https://user-images.githubusercontent.com/62474292/99639367-da39b300-2a8a-11eb-9fce-bbcfa09b458d.JPG)

- who is this user like?
- Is this a house that people tend to rate highly? <br>
The preicted rating is a combination of both these factors.

#### Last problem = Infrastructure
How often and where will you compute the predicted ratings?
![streaming](https://user-images.githubusercontent.com/62474292/99650347-a36a9980-2a98-11eb-930b-fcf6de158c83.JPG)
**batch or streaming** 
- batch : don't need to update the rental recommendations every time a new rating appears in our system
- streaming : compute the rating that every user will give every house -> do it in a big data platform like Apache Hadoop

### Finally, where will you store the computed ratings?
![data](https://user-images.githubusercontent.com/62474292/99651233-a87c1880-2a99-11eb-9782-29247992c9e5.JPG)

we probably want to power a web application with these recommendations and we don't want to compute recommendations when the user reads a webpage. <br>
We want to precompute these recommendations (batch jobs)

### So we need a transactional way to store the predictions.

 While the user is reading these predictions, we can update the predictions table as well.<br>
 store the data in a relational database management system, an RDBMS like my SQL.
 
 ### How to migrate the recommendation system from on-premises to Google Cloud Platform
 
![spark](https://user-images.githubusercontent.com/62474292/99697995-9d45de80-2ad3-11eb-9a22-53cd54bf6fc8.JPG)
 
 - Use SparkML, but instead of doing it on-premises, we'll run the machine learning job on Cloud Dataproc.
 - Then store the ratings in an RDBMS in Cloud SQL, because this is a relatively small dataset of five recommendations for every user.
 
![cloud](https://user-images.githubusercontent.com/62474292/99698019-a33bbf80-2ad3-11eb-86c9-1afb66a26928.JPG)

**use Cloud Storage** as a global file system.<br>
**Use Cloud SQL** as an RDBMS as a relational database management system for transactional relational data that you access through SQL.<br>
**Use Datastore** as a transactional No-SQL object-oriented database.<br>
**Use Bigtable** for high-throughput No-SQL append-only data.,So not transactions, append-only data.,So a typical use case for Bigtable is sensor data for connected devices for example.<br>
**Use BigQuery** as a SQL data warehouse to power all your analytics needs.<br>

![visual](https://user-images.githubusercontent.com/62474292/99698039-a931a080-2ad3-11eb-904f-ccf165919bf7.JPG)
If your data is **unstructured**, like images or audio, use **Cloud Storage**. <br>
If your data is **structured** and you need transactions, use **Cloud SQL or Cloud Datastore**, depending on whether you want your access pattern to be SQL or No-SQL, and by No-SQL we mean a key-value pair. <br>
In other words, you'll be trying to search for data based on a single key, **use Datastore** <br>
if you'd be finding data using SQL use **Cloud SQL**. <br>
**Cloud SQL** generally plateaus out at a few gigabytes. <br>
So if you wanted transactional database that is horizontally scalable so that you can deal with data larger than a few gigabytes, or if you need multiple databases so you want them spread globally, use **Cloud Spanner**. (If you'll need multiple databases, either because you have a lot of data or because your application needs to be transactional across different continents)<br>
If your data is **structured and you want Analytics,** consider either Bigtable or BigQuery. <br>
**Use Bigtable** if you need real-time high-throughput applications. <br>
**Use BigQuery** if you want Analytics over petabyte-scale datasets. <br>

