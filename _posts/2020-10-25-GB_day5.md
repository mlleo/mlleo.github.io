---
title: "[Google_Bootcamp_Day5]"
categories: 
  - ML
last_modified_at: 2020-10-25 12:00:00
comments: true
use_math: true # MathJax On
---

#### Parameters W and B
![1](https://user-images.githubusercontent.com/62474292/102813233-ced00380-440b-11eb-91c9-f9b7159a8118.png)

#### Vectorized Implementation
![2](https://user-images.githubusercontent.com/62474292/102813237-d099c700-440b-11eb-8d96-125f96763671.png)

#### Intuition about deep representation
![3](https://user-images.githubusercontent.com/62474292/102813254-d8596b80-440b-11eb-80d6-ca69f4e9cd63.png)

#### Building blocks of deep neural networks
![4](https://user-images.githubusercontent.com/62474292/102813231-cd9ed680-440b-11eb-8424-b3afc12c62ef.png)
![5](https://user-images.githubusercontent.com/62474292/102813240-d1caf400-440b-11eb-905d-c255a24fcc88.png)

#### Forward and Backward propagation
- Forward propagation for layer l
![6](https://user-images.githubusercontent.com/62474292/102813252-d7283e80-440b-11eb-956b-a7ccb4adeb6d.png)

- Backward propagation for layer l
![7](https://user-images.githubusercontent.com/62474292/102813243-d2fc2100-440b-11eb-8148-34ceb96cc17c.png)

- Summary
![8](https://user-images.githubusercontent.com/62474292/102813248-d5f71180-440b-11eb-8cfe-443bc25cc6e4.png)

#### Hyperparameters
- Parameters : W[1], b[1], W[2], b[2], ...
- Hyperparameters
  - learning rate
  - number of iterations
  - number of hidden layers
  - number of hidden units
  - choice of activation functions
  - momentum
  - mini-batch size
  - regularization
  - etc ...
  
#### Final review for forward and backward propagation
![9](https://user-images.githubusercontent.com/62474292/102813245-d42d4e00-440b-11eb-9a26-4e2758999b28.png)



[Source] https://www.coursera.org/learn/neural-networks-deep-learning
