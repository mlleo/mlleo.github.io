---
title: "[Google_Bootcamp_Day30]"
categories: 
  - ML
last_modified_at: 2020-12-01 12:00:00
comments: true
use_math: true # MathJax On
---
Algorithms for learning word embeddings

#### Neural language model

- Other contexts( ways to predict target words)
  - Last 4 words
  - 4 words on left & right
  - Last 1 word
  - Nearby 1word
  If you really want to build a language model, it's natural to use the last few words as a context. But if your main goal is really to learn a word embedding, then you can use all of these other contexts and they will result in very meaningful work embeddings as well
  

#### Skip-grams

[Source] https://www.coursera.org/learn/nlp-sequence-models
