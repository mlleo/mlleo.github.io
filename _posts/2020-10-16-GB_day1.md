---
title: "[Google_Bootcamp_Day1]"
categories: 
  - ML
last_modified_at: 2020-11-03 12:00:00
comments: true
use_math: true # MathJax On
---
#### Google Machine Learning Bootcamp (Coursera Deep Learning Specialization)

GB(Google Bootcamp) series is based on the coursera lecture **"Deep Learning Specialization".**
These posts are for my review of basic machine learning, but I also hope that it could be helpful for others.<br><br>

- If you've done coursera lecture "Deep Learning Specialization", then it would be perfect for you to remind. <br>
- If you studied basic machine learning before, it could be nice to wrap up your knowledge. <br>
- If you haven't studied basic machine learning before, then I recommend you to use this blog posts as supplementary materials with **other full-organized materials(books, lectures, etc.)**

#### Standard notations for Deep Learning 
![notation](https://user-images.githubusercontent.com/62474292/102651645-430e6b00-41b0-11eb-8e1f-83a0c334ee82.png)

#### Binary Classification
- The result is a discrete value output
- Goal is to learn a classifier that can input an image represented by feature vector x, and predict whether the corresponding label y is 1 or 0, that is, whether this is a cat image or a non-cat image
![image](https://user-images.githubusercontent.com/62474292/102651642-4144a780-41b0-11eb-91b7-0cc95a602c3b.png)
- An image is stored in the computer in three separate matrices corresponding to Red, Green and Blue color channels of the image
- To create a feature vecotr x, the pixel value will be "reshape" for each color
- Dimension of the input feature vector x is n_x = 64 * 64 * 3 = 12,288
![feature_vector](https://user-images.githubusercontent.com/62474292/102651648-443f9800-41b0-11eb-9e23-2f57acc02640.png)

#### Logistic Regression
- A learning algorithm used in a supervised learning problem when the output y are either 0 or 1
- Goal of logistic regression is to minimize the error between its predictions and training data
![logistic](https://user-images.githubusercontent.com/62474292/102656125-bc10c100-41b6-11eb-8329-21bc1d61f150.png)
- wTx + b is a linear function, but since we are looking for a probability constraint between 0 and 1, so the sigmoid function is used
- If z is a large positive number, then sigma(z) = 1
- If z is small or large negative number, then sigma(z) = 0
- If z = 0, then sigma(z) = 0.5

#### Logistic Regression Cost function

1. Loss function
- The loss function measures the discrepancy between the prediction(y_hat) and the desired output(y)
- computes the error for a single training example
