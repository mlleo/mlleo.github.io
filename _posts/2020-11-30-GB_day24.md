---
title: "[Google_Bootcamp_Day24]"
categories: 
  - ML
last_modified_at: 2020-11-29 12:00:00
comments: true
use_math: true # MathJax On
---

Sequence Models

#### Examples of Sequence problem
- Speech recognition
- Music generation
- Sentiment classification
- DNA sequence analysis
- Machine translation
- Video activity recognition
- Name entity recognition
- etc...

#### Notation example in Named-entity recognition problem

![word](https://user-images.githubusercontent.com/62474292/100582670-f06a2d80-332c-11eb-8d1f-27409bd7cce8.png)

#### How to represent words
- Based on words dictionary, use one-hot encoding
- Assume dictionary have 10,000 words which means 100 dimensional vector. (Most case dictionary size = 30,000 ~50,000)
- Then every words will be represented to 100 dimensional vector (one-hot encoding)
- Goal is that given this representation for X to learn a mapping using a sequence model to then target output y

#### Why not use standard network?
![standard_nn](https://user-images.githubusercontent.com/62474292/100618753-96369000-335f-11eb-80d9-4f3487482fa1.png)

Problems
  - Inputs, outputs can be different lengths in different examples.
  - Doesn't share features learned across different positions of text.
  
#### Recurrent Neural Networks
![rnn_forward](https://user-images.githubusercontent.com/62474292/100618787-9fbff800-335f-11eb-9403-2df94090080d.png)

Limitation : the prediction at a certain time uses information from the inputs earlier in the sequence but not information later in the sequence.

#### RNN forward propagation
![rnn_not](https://user-images.githubusercontent.com/62474292/100618820-a9496000-335f-11eb-9f09-94634e69aa88.png)

#### Simplified RNN forward propagation notation
![simp_rnn_not](https://user-images.githubusercontent.com/62474292/100618830-acdce700-335f-11eb-9bc1-bea5ca81e808.png)

#### Forward propagation and backpropagation in RNN
![rnn_backprop](https://user-images.githubusercontent.com/62474292/100621429-04308680-3363-11eb-94be-e9e98fac31d7.png)

Loss function
![rnn_loss](https://user-images.githubusercontent.com/62474292/100621439-072b7700-3363-11eb-9bb4-ecec3945b54d.png)

#### Examples of RNN architecture
- many-to-many
- many-to-one
  - sentiment classification (x=text, y=0/1)
- one-to-one
- one-to-many
  - music generation
  
![rnn_model](https://user-images.githubusercontent.com/62474292/100701652-68932a80-33e3-11eb-843e-5023a5b14051.png) <br><br>
  
[Source] https://www.coursera.org/learn/nlp-sequence-models

