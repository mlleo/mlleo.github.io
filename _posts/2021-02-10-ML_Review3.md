---
title: "[ML BASIC REVIEW 3]"
categories: 
  - ML
last_modified_at: 2021-02-10 12:00:00
comments: true
use_math: true # MathJax On
---

#### ML_BASIC_REVIEW 3

#### Collaborative filtering

1. 배경지식
- Collaborative filtering에 대해 알기 전에 우선 추천시스템(Recommendation System)에 대해 알아야 한다. 
- 추천시스템이란 사용자의 취향을 파악해 다른 선택지를 제공해주는 시스템으로서 대표적으로 유투브, 넷플릭스 등 많은 서비스에서 사용되고 있다.
- 추천 시스템은 기본적으로 Content-based filtering 방식과 Collaborative filtering 방식이 존재한다.
- Content-based filtering 방식은 현재로서는 많이 사용되지는 않는다.(아래에 간략히 설명!)

2. Content-based filtering
- 사용자가 특정 아이템을 선호하는 경우 그 아이템과 비슷한 컨텐츠를 가진 다른 아이템을 추천해주는 방식이다.
- 예를 들어 사용자 A가 마블 관련 영화 X에 굉장히 높은 평점을 주었다면 다른 마블 영화를 추천해주는 것이다.
  ![CONTENT](https://user-images.githubusercontent.com/62474292/107618528-0c773d00-6c95-11eb-87a1-7da886817a87.JPG)

3. Collaborative filtering
- 많은 사용자로부터 얻은 취향 정보(user behavior)를 기반으로 하여 스스로 추천해주는 기술을 의미한다.
- Collaborative filtering은 nearest neighbor collaborative filtering (item-based, user-based)와 latent factor based collaborative filtering으로 나누어진다.

4. Nearest neighbor collaborative filtering
- User-Item matrix에서 사용자가 아직 평가하지 않은 아이템을 예측하는 것이 목표 <br>
  ![표1](https://user-images.githubusercontent.com/62474292/107643779-f16af400-6cb9-11eb-9274-56174ec009ce.JPG)
  ![표2](https://user-images.githubusercontent.com/62474292/107643781-f2038a80-6cb9-11eb-899b-520566430b80.JPG)
- 위 표의 예시를 보면 사용자 A와 B 모두 ItemA, ItemB, ItemC에 대해서 비슷한 평점을 주었으므로 사용자 A와 B는 유사한 사용자라고 판단(User-based)
- User-based 방식에서는 데이터를 User(row) * Item(column)형태로 바꿔서 판단해야 함
  ![표3](https://user-images.githubusercontent.com/62474292/107644231-853cc000-6cba-11eb-80c9-8da9c76c1ea1.JPG)
- 위 표의 예시를 보면 ItemA와 ItemB가 사용자들로부터 비슷한 평점을 받았으므로 ItemA와 ItemB를 비슷한 아이템이라고 판단(Item-based)
- Item-based 방식에서는 데이터를 Item(row) * User(column)형태로 바꿔서 판단해야 함

- 일반적으로 User-based collaborative filtering보다 Item-based collaborative filtering이 좀 더 정확도가 높다고 알려져 있다.

5. Latent factor based collaborative filtering


#### Few-shot Learning (+GPT-3에서의 의미는?)

#### Federated Learning

#### Central Limit Theorem

1. 정의
- 중심 극한 정리란 '동일한 확률분포를 가진 독립 확률 변수 n개의 표본평균 (X_bar)의 분포는 모집단의 분포에 상관없이 표본의 크기 n이 커질수록 정규분포에 가까워진다'라는 정리이다.
- 정확한 식을 표현하자면, '모집단이 **평균이 μ이고 표준편차가 σ인 임의의 분포**를 이룬다고 할 때, 이 모집단으로부터 추출된 **표본의 크기 n이 충분히 크다면** 표본 평균들이 이루는 분포는 **평균이 μ이고 표준편차가 √σ/μ인 정규분포**에 근접한다.
- 이 때 표본평균분포란 Sampling distribution of sample mean을 의미하는데, 이는 모집단에서 표본크기가 n인 표본을 여러번 반복해서 추출했을 때, 각각의 표본 평균들이 이루는 분포를 의미한다.
- 중심극한정리는 이 때 그 표본의 크기가 일정 수보다 크다면 (일반적으로 30보다 큰 경우를 가정) 표본평균의 분포를 정규분포로 가정할 수 있는 아주 유용한 정리이다.

2. 중요성
- 중심극한정리를 통해 모집단이 어떤 분포를 가지고 있던지 간에 (즉, 모집단 분포와 상관없이) 일단 표본의 크기가 충분히 크다면, 표본평균들의 분포가 모집단의 모수를 기반으로 한 정규분포를 이룬다는 점을 이용하여, 특정 사건(수집한 표본의 평균)이 일어날 확률값을 계산할 수 있다.
- 즉, 표본 평균들이 이루는 표본 분포와 모집단 간의 관계를 증명함으로써, 수집한 표본의 통계량을 이요하여 모집단의 모수를 추정할 수 있는 수학적 근거를 마련해준다.

#### Singular Value Decomposition
