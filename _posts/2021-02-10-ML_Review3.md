---
title: "[ML BASIC REVIEW 3]"
categories: 
  - ML
last_modified_at: 2021-02-10 12:00:00
comments: true
use_math: true # MathJax On
---

#### ML_BASIC_REVIEW 3

#### Collaborative filtering

1. 배경지식
- Collaborative filtering에 대해 알기 전에 우선 추천시스템(Recommendation System)에 대해 알아야 한다. 
- 추천시스템이란 사용자의 취향을 파악해 다른 선택지를 제공해주는 시스템으로서 대표적으로 유투브, 넷플릭스 등 많은 서비스에서 사용되고 있다.
- 추천 시스템은 기본적으로 Content-based filtering 방식과 Collaborative filtering 방식이 존재한다.
- Content-based filtering 방식은 현재로서는 많이 사용되지는 않는다.(아래에 간략히 설명!)

2. Content-based filtering
- 사용자가 특정 아이템을 선호하는 경우 그 아이템과 비슷한 컨텐츠를 가진 다른 아이템을 추천해주는 방식이다.
- 예를 들어 사용자 A가 마블 관련 영화 X에 굉장히 높은 평점을 주었다면 다른 마블 영화를 추천해주는 것이다.
  ![CONTENT](https://user-images.githubusercontent.com/62474292/107618528-0c773d00-6c95-11eb-87a1-7da886817a87.JPG)

3. Collaborative filtering
- 많은 사용자로부터 얻은 취향 정보(user behavior)를 기반으로 하여 스스로 추천해주는 기술을 의미한다.
- Collaborative filtering은 nearest neighbor collaborative filtering (item-based, user-based)와 latent factor based collaborative filtering으로 나누어진다.

4. Nearest neighbor collaborative filtering
- User-Item matrix에서 사용자가 아직 평가하지 않은 아이템을 예측하는 것이 목표
- 아래 표는 기본적으로 DB가 저장하는 형태를 표현한 것! <br>
  ![표1](https://user-images.githubusercontent.com/62474292/107643779-f16af400-6cb9-11eb-9274-56174ec009ce.JPG) <br>
- User-based 방식에서는 데이터를 User(row) * Item(column)형태로 바꿔서 판단해야 함
- 아래 표의 예시를 보면 사용자 A와 B 모두 ItemA, ItemB, ItemC에 대해서 비슷한 평점을 주었으므로 사용자 A와 B는 유사한 사용자라고 판단(User-based) <br>
  ![표2](https://user-images.githubusercontent.com/62474292/107643781-f2038a80-6cb9-11eb-899b-520566430b80.JPG) 
- Item-based 방식에서는 데이터를 Item(row) * User(column)형태로 바꿔서 판단해야 함
- 아래 표의 예시를 보면 ItemA와 ItemB가 사용자들로부터 비슷한 평점을 받았으므로 ItemA와 ItemB를 비슷한 아이템이라고 판단(Item-based) <br>
  ![표3](https://user-images.githubusercontent.com/62474292/107644231-853cc000-6cba-11eb-80c9-8da9c76c1ea1.JPG) <br>
- 일반적으로 User-based collaborative filtering보다 Item-based collaborative filtering이 좀 더 정확도가 높다고 알려져 있다.

5. Latent factor based collaborative filtering


#### Few-shot Learning (+GPT-3 관련해서 추가 정리할 것!)

1. 배경지식
- 딥러닝 모델을 학습하는 데 있어서 가장 중요한 요소 중 하나가 데이터이다.
- 하지만 모델의 정확도를 높이기 위해 충분한 데이터를 확보하는 것은 많은 task에서 비현실적이고 달성하기 어렵다. (라벨링 비용)
- 이러한 제한된 데이터 및 시나리오에서 모델을 학습하기 위한 나온 학습 방법이 Few-shot learning이다.

2. Few-shot learning
- Few-shot learning이란 매우 적은 양의 train set으로 모델을 학습시키는 방법이다.
- 즉, network 학습시 class별로 적은 양의 이미지를 보여주고 network를 학습시키는 것이 Few-shot learning의 process이다.
- 아래 용어들은 Few-shot learning에서 주로 사용되는 용어들이다.
- n-way : 각 batch 별로 선택하는 label의 개수(N)
- K-shot : 각 class별로 선택하는 support data의 개수(K)
- support : 해당 batch에서 fine-tuning을 위해 학습하는 데이터셋 (train set)
- query : 해당 batch에서 class를 예측해야 하는 데이터셋 (test set)
- episode : 한 epoch당 수행하는 iteration 횟수 <br>
  ![meta](https://user-images.githubusercontent.com/62474292/107664101-698fe480-6ccf-11eb-8b8f-56f589b9c971.JPG) <br>
- Few-Shot Learning 에서 기존 Classification과의 가장 큰 차이점은 Sampling 수행 시 label의 index가 계속 바뀐다는 점이다 
- 위의 그림에서 알 수 있듯이 few-shot learning으로 학습한 모델이 잘 동작하기 위해서는 meta-learning이 필요한데 이 과정에서 다양한 task에 대해 episodic training을 진행하게 된다. 이러한 episodic training은 few-shot task와 유사한 형태의 train task를 통해 모델 스스로 학습 규칙을 도달해서 일반화 성능을 높일 수 있게 도와준다. 이 때, 각 task별로 support set이 sampling된 후 에 label의 index가 정해지기 때문에 기존 classification과는 다르다.


#### Federated Learning

1. Federated Learning Process
- 1. 수집된 데이터를 통해 server에서 모델을 학습시킨다
- 2. 
#### Central Limit Theorem

1. 정의
- 중심 극한 정리란 '동일한 확률분포를 가진 독립 확률 변수 n개의 표본평균 (X_bar)의 분포는 모집단의 분포에 상관없이 표본의 크기 n이 커질수록 정규분포에 가까워진다'라는 정리이다.
- 정확한 식을 표현하자면, '모집단이 **평균이 μ이고 표준편차가 σ인 임의의 분포**를 이룬다고 할 때, 이 모집단으로부터 추출된 **표본의 크기 n이 충분히 크다면** 표본 평균들이 이루는 분포는 **평균이 μ이고 표준편차가 √σ/μ인 정규분포**에 근접한다.
- 이 때 표본평균분포란 Sampling distribution of sample mean을 의미하는데, 이는 모집단에서 표본크기가 n인 표본을 여러번 반복해서 추출했을 때, 각각의 표본 평균들이 이루는 분포를 의미한다.
- 중심극한정리는 이 때 그 표본의 크기가 일정 수보다 크다면 (일반적으로 30보다 큰 경우를 가정) 표본평균의 분포를 정규분포로 가정할 수 있는 아주 유용한 정리이다.

2. 중요성
- 중심극한정리를 통해 모집단이 어떤 분포를 가지고 있던지 간에 (즉, 모집단 분포와 상관없이) 일단 표본의 크기가 충분히 크다면, 표본평균들의 분포가 모집단의 모수를 기반으로 한 정규분포를 이룬다는 점을 이용하여, 특정 사건(수집한 표본의 평균)이 일어날 확률값을 계산할 수 있다.
- 즉, 표본 평균들이 이루는 표본 분포와 모집단 간의 관계를 증명함으로써, 수집한 표본의 통계량을 이요하여 모집단의 모수를 추정할 수 있는 수학적 근거를 마련해준다.

#### Singular Value Decomposition
